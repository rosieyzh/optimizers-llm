max_duration: 25000 # 3.3B tokens / (256 batch * 512 context) (20x number of parameters) 

device_train_microbatch_size: 128 # For H100 with adam

model:
  # 150m non-embedding params and 216m total params
  d_model: 1024
  n_heads: 16
  mlp_hidden_size: 4096
  n_layers: 12

# Memory: 51GB
# 300k tokens / sec or 2.3 batches / sec
# ~3 hrs per run